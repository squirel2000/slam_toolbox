{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "void CeresSolver::AddConstraint(karto::Edge<karto::LocalizedRangeScan> * pEdge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.130860978829012, -0.6332133625089302, 1.2727047169999999)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The pose difference with respect to a reference pose (pose1 in this case), \n",
    "# involves translating the second pose into the coordinate frame of the first pose.\n",
    "import numpy as np\n",
    "\n",
    "def normalize_angle(angle):\n",
    "    \"\"\"Normalize angle to be within the interval [-pi,pi].\"\"\"\n",
    "    return np.arctan2(np.sin(angle), np.cos(angle))\n",
    "\n",
    "def pose_difference(pose1, pose2):\n",
    "    # Extract the coordinates and orientations\n",
    "    x1, y1, theta1 = pose1\n",
    "    x2, y2, theta2 = pose2\n",
    "\n",
    "    # Translate pose2 by the negative of the translation of pose1\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "\n",
    "    # Rotate this translated pose by the negative of the orientation of pose1\n",
    "    x_diff = dx * np.cos(theta1) + dy * np.sin(theta1)\n",
    "    y_diff = -dx * np.sin(theta1) + dy * np.cos(theta1)\n",
    "\n",
    "    # Normalize the orientation difference\n",
    "    theta_diff = normalize_angle(theta2 - theta1)\n",
    "\n",
    "    return (x_diff, y_diff, theta_diff)\n",
    "\n",
    "# Define the poses\n",
    "pose1 = (2.95077, 3.19863, -1.27301)\n",
    "pose2 = (2.97063, 0.975764, -0.000305283)\n",
    "\n",
    "# Calculate the pose difference\n",
    "pose_diff = pose_difference(pose1, pose2)\n",
    "pose_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 313.73306355,  106.42873658,    0.        ],\n",
       "       [ 106.42873658,  573.92967469,    0.        ],\n",
       "       [   0.        ,    0.        , 7594.40701233]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the covariance matrix\n",
    "covariance_matrix = np.array([\n",
    "    [0.00340139451530056, -0.000630749962635198, 0  ],\n",
    "    [-0.000630749962635198, 0.00185933916413766, 0 ],\n",
    "    [0, 0, 0.000131675850185091]\n",
    "])\n",
    "\n",
    "# Calculate the inverse of the covariance matrix\n",
    "inverse_covariance_matrix = np.linalg.inv(covariance_matrix)\n",
    "inverse_covariance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.7125115 ,  0.        ,  0.        ],\n",
       "       [ 6.00867565, 23.19106491,  0.        ],\n",
       "       [ 0.        ,  0.        , 87.14589498]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLT Decomposition and matrixU Details:\n",
    "# LLT decomposition is used to factorize a positive-definite matrix into the product of a lower triangular matrix and its transpose. \n",
    "# It is essentially a Cholesky decomposition, which is a special case of LU decomposition where the matrix being decomposed is symmetric and positive-definite.\n",
    "\n",
    "# Calculate the The LLT decomposition of the inverse covariance matrix\n",
    "LLT_decomposition = np.linalg.cholesky(inverse_covariance_matrix)\n",
    "LLT_decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 586.49432451,   -0.        ,    0.        ],\n",
       "       [  -0.        ,  618.48500126,    0.        ],\n",
       "       [   0.        ,    0.        , 8392.7852521 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLT_decomposition * LLT_decomposition.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of zero rows: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Jacobian matrix from the CSV file\n",
    "jacobian_df = pd.read_csv('/home/asus/colcon_ws/src/asus_amr/logs/jacobian.csv', delimiter=' ', header=None)\n",
    "\n",
    "# Check for zero rows\n",
    "zero_rows = jacobian_df[(jacobian_df.T == 0).all()]\n",
    "\n",
    "# Print the indices of the zero rows, if any\n",
    "print(\"Indices of zero rows:\", zero_rows.index.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
